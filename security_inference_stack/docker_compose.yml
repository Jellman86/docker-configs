services:
#-----------------------------------------------
  frigate:
    container_name: frigate
    restart: unless-stopped
    stop_grace_period: 30s # allow enough time to shut down the various services
    image: ghcr.io/blakeblackshear/frigate:stable
    shm_size: "512mb" # update for your cameras based on calculation above
    devices:
      - /dev/dri:/dev/dri
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ${DOCKERCONFIGPATH}/frigate/config:/config
      - ${DOCKERCONFIGPATH}/frigate/media:/media/frigate
      - type: tmpfs # Optional: 1GB of memory, reduces SSD/SD Card wear
        target: /tmp/cache
        tmpfs:
          size: 1000000000
    networks:
        service_mac_vlan:
          ipv4_address: 192.168.213.131
        general_brg:
    ports:
      - "8971:8971"
      - "5000:5000" # Internal unauthenticated access. Expose carefully.
      - "8554:8554" # RTSP feeds
      - "8555:8555/tcp" # WebRTC over tcp
      - "8555:8555/udp" # WebRTC over udp
    environment:
      - FRIGATE_RTSP_PASSWORD=${FRIGATE_RTSP_PASSWORD}
      - TZ=Europe/London
      - PUID=568
      - PGID=568
#-----------------------------------------------
  birdnet-go:
    image: ghcr.io/tphakala/birdnet-go:nightly
    container_name: birdnet-go
    restart: unless-stopped
    ports:
      - "${WEB_PORT:-8080}:8080"
    networks:
        general_brg:
    environment:
      - TZ=Europe/London
      - BIRDNET_UID=1000
      - BIRDNET_GID=1000
      # BirdNET Configuration
      # Currently configured for the rents place. 
      - BIRDNET_LOCALE=en-uk                      # Locale code (2-10 chars, e.g., "en" or "en-us")
      - BIRDNET_LATITUDE=${loclat}                 # Valid range: -90.0 to 90.0
      - BIRDNET_LONGITUDE=${loclong}              # Valid range: -180.0 to 180.0
      - BIRDNET_SENSITIVITY=1.0                   # Valid range: 0.1 to 1.5 (higher = more sensitive)
      - BIRDNET_THRESHOLD=0.7                     # Valid range: 0.0 to 1.0 (confidence threshold)
      - BIRDNET_OVERLAP=1.5                       # Valid range: 0.0 to 2.9 seconds (audio chunk overlap)
      - BIRDNET_THREADS=0                         # 0 = auto (use all CPUs), or specify number of threads
      - BIRDNET_DEBUG=false                       # Enable debug logging (true/false)
      - BIRDNET_USEXNNPACK=true                   # Use XNNPACK acceleration (true/false)
      # Range Filter Configuration               
      - BIRDNET_RANGEFILTER_MODEL=latest
      - BIRDNET_RANGEFILTER_THRESHOLD=0.01
    volumes:
      - ${DOCKERCONFIGPATH}/birdnet-go/config:/config
      - ${DOCKERCONFIGPATH}/birdnet-go/data:/data
    tmpfs:
      - /config/hls:exec,size=50M,uid=${BIRDNET_UID:-568},gid=${BIRDNET_GID:-568},mode=0755
#-----------------------------------------------
  homeassistant:
    image: ghcr.io/home-assistant/home-assistant:stable
    container_name: homeassistant
    restart: unless-stopped
    user: "568:568"
    environment:
      - TZ=Europe/London
    volumes:
      - ${DOCKERCONFIGPATH}/homeassistant/config:/config
      - /etc/localtime:/etc/localtime:ro
    networks:
      - general_brg
    ports:
      - "8123:8123"
#-----------------------------------------------
  matter-server:
    image: ghcr.io/home-assistant-libs/python-matter-server:stable
    container_name: matter-server
    restart: unless-stopped
    user: "568:568"
    environment:
      - TZ=Europe/London
    networks:
      - general_brg
    ports:
      - "5580:5580"
      - "5540:5540"
    volumes:
      - ${DOCKERCONFIGPATH}/matter-server/data:/data:rw
      - /run/dbus:/run/dbus:ro
#-----------------------------------------------
  mosquitto:
    image: eclipse-mosquitto:latest
    container_name: mosquitto
    restart: unless-stopped
    user: "568:568"
    environment:
      - TZ=Europe/London
    networks:
      - general_brg
    ports:
      - "1883:1883"
    volumes:
      - ${DOCKERCONFIGPATH}/mosquitto/config:/mosquitto/config
      - ${DOCKERCONFIGPATH}/mosquitto/data:/mosquitto/data
      - ${DOCKERCONFIGPATH}/mosquitto/log:/mosquitto/log
#-----------------------------------------------
  ollama-xpu:
    image: intelanalytics/ipex-llm-inference-cpp-xpu:latest
    container_name: ollama-xpu
    restart: unless-stopped
    networks:
      - general_brg
    ports:
      - "11434:11434"
    user: "568:568"
    environment:
      - TZ=Europe/London
      - OLLAMA_HOST=0.0.0.0:11434
      - ZES_ENABLE_SYSMAN=1
      - USE_XETLA=OFF
      # choose an appropriate device string for your GPU/iGPU
      - DEVICE=GPU
    devices:
      - /dev/dri:/dev/dri
    volumes:
      - ${DOCKERCONFIGPATH}/ollama_data:/llm/ollama
      - ${DOCKERCONFIGPATH}/models_data:/llm/models
    command: >
      bash -lc '
        set -e
        cd /llm/scripts/
        # Try to init IPEX-LLM env; if it fails, continue without it
        if ! source ipex-llm-init --gpu --device "$DEVICE"; then
          echo "ipex-llm-init failed, continuing without extra env"
        fi

        # Start Ollama in background
        bash start-ollama.sh &

        # Give the server a moment to start
        sleep 10

        # Pull model once if not present
        cd /llm/ollama
        if ! ./ollama list | grep -q "llama3.2:8b"; then
          ./ollama pull llama3.2:8b
        fi

        # Keep container alive and stream logs
        tail -f /llm/ollama/ollama.log
      '
#-----------------------------------------------
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: unless-stopped
    networks:
      - general_brg
    ports:
      - "8188:8080"
    user: "568:568"
    environment:
      - TZ=Europe/London
      # Point WebUI at the GPU-accelerated Ollama service
      - OLLAMA_BASE_URL=http://ollama-xpu:11434
    depends_on:
      - ollama-xpu
    volumes:
      # Map to dataset if desired, e.g. /mnt/tank/ai/openwebui
      - ${DOCKERCONFIGPATH}/openwebui_data:/app/backend/data
#-----------------------------------------------
networks:
    service_mac_vlan:
      external: true
    general_brg:
      external: true